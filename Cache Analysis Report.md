# Cache Analysis Report

* 计72 邹振华 2017011464

## 实验环境

Win10

VS Code 1.43.2

gcc 6.3.0

GNU Make 3.82.90



## 实现过程

我设计了一个TraceSimulator类用于模拟Cache，并针对不同的替换策略设计了不同的替换器类(包含Replacer，LRU_Replacer, RANDOM_Replacer, BINARY_TREE_Replacer)用于执行替换操作，并在替换发生时维护相应数据。针对不同的写策略设计了不同的写类(包含Writer, ALLOC_THROUGH_Writer, ALLOC_BACK_Writer, UNALLOC_THROUGH_Writer, UNALLOC_BACK_Writer)完成不同策略下的写操作，其中调用了Replacer类的相关接口执行必要的更新和替换操作。

此外，为了充分利用cache空间，需要执行bit操作，因此我在utils.h和utils.cpp中定义了多重载的setBits函数，用于设置bit位和读取bit位。实现思路较为简单，就是给定source串和target串的起点s_begin, t_begin, 逐个bit位读取source串，同时设置target串的响应位。TraceSimulator类中声明了一系列变量用于维护cache的结构信息，包含：

```c++
        unsigned int cache_line_num;
        unsigned int way_num;
        unsigned int meta_size;
        unsigned int entry_size;
        unsigned int offset_bit_width;
        unsigned int index_bit_width;
        unsigned int tag_bit_width;
```



TraceSimulator在基于命令行参数进行初始化的时候计算了必要的cache block对应的index宽度，tag宽度，offset宽度，结合valid位和dirty位进而获取meta数据宽度，并进一步得出cache line的长度。cache line采用二维unsigned char数组存储，LRU链表和Binary Tree均采用unsigned char数组存储，使用setBits的某个重载函数进行访问。



## 缺失率统计

### 对照组一  LRU, ALLOC, Write Back

* 每个数据格中的四个数据，从左到右，从上到下依次为astar.trace, bzip2.trace, mcf.trace, perlbench.trace的缺失率

|          | 8B                                     | 32B                                    | 64B                                    |
| -------- | -------------------------------------- | -------------------------------------- | -------------------------------------- |
| 全相联   |                                        |                                        |                                        |
| 直接映射 | 0.233961, 0.020615, 0.049447, 0.036668 | 0.098377, 0.013311, 0.021968, 0.023138 | 0.052681, 0.015897, 0.014595, 0.018940 |
| 4-way    | 0.232791, 0.012170, 0.045759, 0.020712 | 0.096299, 0.003063, 0.018245, 0.011357 | 0.050099, 0.001544, 0.010837, 0.008531 |
| 8-way    | 0.232848, 0.012170, 0.045759, 0.017902 | 0.096275, 0.003063, 0.018245, 0.008222 | 0.050001, 0.001544, 0.010837, 0.006245 |

**分析**

观察数据可以发现，其他cache条件相同时候，对于任何一个trace，缺失率, 8路组相联 < 4路组相联 < 直接映射，这与课上介绍的知识是相符合的，相联路数越多，每一个index可以存放的块数就越大，进而降低缺失率；对于cache块的大小，一般而言，cache块越大，缺失率越低，因为一般的内存访问具有很强的局部性，增加cache块大小很好的利用了这种局部性。但是也有反例，比如bzip2.trace的直接映射缺失率中32B block要比64B block小，这可能是部分段的trace命令的局部性较小造成的。



### 对照组二  8B, 8-way, Write Back

|                 | LRU      | Random   | Binary Tree |
| --------------- | -------- | -------- | ----------- |
| astar.trace     | 0.232848 | 0.232844 | 0.235299    |
| bzip2.trace     | 0.012170 | 0.012714 | 0.013998    |
| mcf.trace       | 0.045759 | 0.046195 | 0.046000    |
| perlbench.trace | 0.017902 | 0.022209 | 0.077353    |

**分析**

观察发现Binary Tree和LRU替换策略的缺失率相近，这和预期是符合的，因为Binary Tree本身是对LRU替换策略的一种近似。总体而言二者的确实率要低于Random，但是相差也不大。这可能是因为相联的路数并不多，而且对于一些顺序性的循环访问序列，LRU策略很可能追着自己的尾巴跑，上一步访问被替换的块很可能是下一步要访问的，这种情况下Random替换策略相比LRU策略其实有更强的适应性。



### 对照组三  8B, 8-way, LRU

|                 | ALLOC_THROUGH | ALLOC_BACK | UNALLOC_THROUGH | UNALLOC_BACK |
| --------------- | ------------- | ---------- | --------------- | ------------ |
| astar.trace     | 0.232848      | 0.232848   | 0.344989        | 0.344989     |
| bzip2.trace     | 0.012170      | 0.012170   | 0.086699        | 0.086699     |
| mcf.trace       | 0.045759      | 0.045759   | 0.111469        | 0.111469     |
| perlbench.trace | 0.017902      | 0.017902   | 0.046634        | 0.046634     |

**分析**

分析不难发现，写回策略和写直达策略的区别对cache访问的确实率并没有影响，因为这两种情况下经过相同的访存序列，cache中存放的数据是相同的。只是写直达的数据总是保存clean，而写回的数据只有被替换写回的时候才回复clean，因此区别在于内存中的内容。但在实际cache系统设计中，写直达策略会增大单次写的耗时，降低cache性能，写回策略虽然能保持cache的性能，但其一致性保持的实现复杂程度较高。

而写分配和写不分配策略的区别对cache缺失率的影响就比较大，对于实验所用的几个trace文件，写分配策略的缺失率要明显低于写不分配策略。这是因为写分配策略能够适应先写后读这种内存访问模式，这种情况下写不分配策略只能一直往内存里写，直到出现往内存读，cache中一直没有加载要访问的数据块，效率自然低。实际cache系统设计中，写分配意味着额外的替换开销，要读写内存各一次，而写直达只写内存一次，因此写分配的缺失率虽然低，但是也会增加单条访存指令的平均执行时间。



## 实验总结

进一步观察以上数据可以发现，不同映射规则、不同块大小、不同替换策略、不同写策略对于cache缺失率的影响大小本身也很依赖于不同的trace文件，cache结构的变化对于有的trace文件的缺失率影响较大，对有的trace文件的影响则较小。其他cache条件完全相同的时候，不同trace文件得出的缺失率相差也很大，因此cache本身的效率如何不仅和cache结构设计相关，也和程序的访存指令序列紧密相关。可见设计好的程序、利用好数据访问的局部性对于充分发挥cache性能、提高任务执行效率意义重大。

本次实验中，设计cache模拟器、Replacer、Writer、bitSet工具的功能解耦花了不少时间。而且由于实现各个模块的正确性测试不足，最后调试也花了很多时间。这里要感谢室友张雨潇的调试建议，即对于某个特定的cache line，比如我采用的是index为0x0ff的cache line，抽取出对应的所有访问指令(并不是很多)，跟踪cache系统的更新过程，看是否有问题。这个调试方法确实十分管用。

实验帮助我理解了cache系统的访问方式，通过不同的Cache结构之间的差异和性能比较，我对Cache访问缺失率的影响因素有了更深的认识，也意识到提高程序访存局部性、充分利用cache对于提高程序性能的重要性。